{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# binary error definition\n",
    "def bin_classification_err(real_y, y):\n",
    "    len_data = y.size\n",
    "    num_diff = 0.0\n",
    "    for i in range(len_data):\n",
    "        if (y[i] != real_y[i]):\n",
    "            num_diff += 1.0\n",
    "    return (num_diff / len_data)\n",
    "\n",
    "\n",
    "# Handle missing values in data\n",
    "def missing_values(original_data, method='omit', \n",
    "                   supply_data=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "                                15,16,17,18,19,20,21,22,23,24,25,26]):\n",
    "    \"\"\"\n",
    "    Replace missing values in original data according to given rules.\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_data : numpy array\n",
    "        The data set containing NaN.\n",
    "    method : str, optional\n",
    "        'omit' : remove rows containing NaN. Default.\n",
    "        'mean' : replace NaN by the mean of its column.\n",
    "        'median' : replace NaN by the median of its column.\n",
    "        'zeros' : replace NaN by 0.\n",
    "        'change_and_add_flags' : replace NaN by the values specified in \n",
    "         supply_data at each corresponding columns. Then add new columns \n",
    "         with 0 = not NaN and 1 = is NaN.\n",
    "    supply_data : list of floats, optional\n",
    "        values to replace NaN in each column. The default is \n",
    "        [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26].\n",
    "        'imputation' : fill in missing values by simple machine learning\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : numpy array of size (row_original_data, \n",
    "               column_original_data + n_column_containing_missing)\n",
    "        The processed data array.\n",
    "    \"\"\"\n",
    "    if method == 'omit':\n",
    "        new_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        \n",
    "    elif method == 'mean':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        mean_row = np.mean(non_nan_data, axis=0)\n",
    "        for i_column in range(len(mean_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=mean_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'median':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        median_row = np.median(non_nan_data, axis=0)\n",
    "        for i_column in range(len(median_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=median_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'zeros':\n",
    "        new_data = np.nan_to_num(original_data, nan=0.0)\n",
    "        \n",
    "    elif method == 'change_and_add_flags':\n",
    "        import numpy.ma as ma\n",
    "        for i_column in range(27): # 27 columns in total, not including y\n",
    "            new_column = np.zeros(len(original_data[:,i_column]))\n",
    "            mask = np.ma.masked_invalid(original_data[:,i_column]).mask\n",
    "            new_column[mask] = 1\n",
    "            if np.sum(new_column) != 0:\n",
    "                new_column = np.expand_dims(new_column, axis=0)\n",
    "                new_column = new_column.transpose()\n",
    "                original_data = np.insert(original_data, [-1], new_column, axis=1)\n",
    "                original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=supply_data[i_column])\n",
    "                new_data = original_data\n",
    "                \n",
    "    elif method == 'imputation':\n",
    "        # to do\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print('Invalid option for treating missing data.')\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "# Parse from csv files\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "# Convert data and deal with missing values\n",
    "dtrain = df_train.values[1:]\n",
    "dtest = df_test.values[:]\n",
    "dtest = missing_values(dtest, method = \"zeros\")\n",
    "dtrain = missing_values(dtrain, method = \"zeros\")\n",
    "\n",
    "# Separate validation and training data\n",
    "X_all, Y_all = dtrain[:, :-1], dtrain[:, -1]\n",
    "X_val = X_all[0:10000]\n",
    "X_train = X_all[10000:(len(X_all) - 1)]\n",
    "Y_val = Y_all[0:10000]\n",
    "Y_train = Y_all[10000:(len(Y_all) - 1)]\n",
    "X_test = dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to make and train classifiers\n",
    "\n",
    "# Make and train a RandomForestClassifier\n",
    "def get_forest(n_estimators, depth, X, Y):\n",
    "    clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = depth, criterion = 'gini')\n",
    "    clf.fit(X, Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf1 validation error: 0.602106069174252\n",
      "rf2 validation error: 0.5992959889924397\n",
      "gbc validation error: 0.6103070636459774\n",
      "xgb validation error: 0.6098181558715685\n",
      "cat validation error: 0.6127258088735674\n",
      "eclf validation error: 0.6113878620774853\n"
     ]
    }
   ],
   "source": [
    "# Try out Voting Classifier\n",
    "\n",
    "X = X_train[:200000]\n",
    "Y = Y_train[:200000]\n",
    "random_state = 54321\n",
    "\n",
    "clfs = []\n",
    "wts = []\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=250, criterion='entropy',  n_jobs = -1,  random_state=random_state)\n",
    "rf1.fit(X, Y)\n",
    "# Get validation error\n",
    "val_probs = rf1.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"rf1 validation error:\", val_err)\n",
    "clfs.append(('rf1', rf1))\n",
    "wts.append(1)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=250, criterion='gini',  n_jobs = -1, random_state=random_state)\n",
    "rf2.fit(X, Y)\n",
    "val_probs = rf2.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"rf2 validation error:\", val_err)\n",
    "clfs.append(('rf2', rf2))\n",
    "wts.append(1)\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "gbc.fit(X, Y)\n",
    "val_probs = gbc.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"gbc validation error:\", val_err)\n",
    "clfs.append(('gbc', gbc))\n",
    "wts.append(3)\n",
    "\n",
    "xgb = XGBClassifier(seed=random_state)\n",
    "xgb.fit(X, Y)\n",
    "val_probs = xgb.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"xgb validation error:\", val_err)\n",
    "clfs.append(('xgb',xgb))\n",
    "wts.append(3)\n",
    "\n",
    "train_pool = Pool(data=X,label = Y)\n",
    "cat = CatBoostClassifier(logging_level='Silent')\n",
    "cat.fit(train_pool, plot=False,silent=True)\n",
    "val_probs = cat.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"cat validation error:\", val_err)\n",
    "clfs.append(('cat', cat))\n",
    "wts.append(2)\n",
    "\n",
    "eclf = VotingClassifier(estimators=clfs, voting='soft')\n",
    "eclf.fit(X, Y)\n",
    "val_probs = eclf.predict_proba(X_val)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"eclf validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = eclf.predict_proba(X_test)[:,1]\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
