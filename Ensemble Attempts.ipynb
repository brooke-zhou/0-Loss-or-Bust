{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# binary error definition\n",
    "def bin_classification_err(real_y, y):\n",
    "    len_data = y.size\n",
    "    num_diff = 0.0\n",
    "    for i in range(len_data):\n",
    "        if (y[i] != real_y[i]):\n",
    "            num_diff += 1.0\n",
    "    return (num_diff / len_data)\n",
    "\n",
    "\n",
    "# Handle missing values in data\n",
    "def missing_values(original_data, method='omit', \n",
    "                   supply_data=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "                                15,16,17,18,19,20,21,22,23,24,25,26]):\n",
    "    \"\"\"\n",
    "    Replace missing values in original data according to given rules.\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_data : numpy array\n",
    "        The data set containing NaN.\n",
    "    method : str, optional\n",
    "        'omit' : remove rows containing NaN. Default.\n",
    "        'mean' : replace NaN by the mean of its column.\n",
    "        'median' : replace NaN by the median of its column.\n",
    "        'zeros' : replace NaN by 0.\n",
    "        'change_and_add_flags' : replace NaN by the values specified in \n",
    "         supply_data at each corresponding columns. Then add new columns \n",
    "         with 0 = not NaN and 1 = is NaN.\n",
    "    supply_data : list of floats, optional\n",
    "        values to replace NaN in each column. The default is \n",
    "        [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26].\n",
    "        'imputation' : fill in missing values by simple machine learning\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : numpy array of size (row_original_data, \n",
    "               column_original_data + n_column_containing_missing)\n",
    "        The processed data array.\n",
    "    \"\"\"\n",
    "    if method == 'omit':\n",
    "        new_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        \n",
    "    elif method == 'mean':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        mean_row = np.mean(non_nan_data, axis=0)\n",
    "        for i_column in range(len(mean_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=mean_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'median':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        median_row = np.median(non_nan_data, axis=0)\n",
    "        for i_column in range(len(median_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=median_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'zeros':\n",
    "        new_data = np.nan_to_num(original_data, nan=0.0)\n",
    "        \n",
    "    elif method == 'change_and_add_flags':\n",
    "        import numpy.ma as ma\n",
    "        for i_column in range(27): # 27 columns in total, not including y\n",
    "            new_column = np.zeros(len(original_data[:,i_column]))\n",
    "            mask = np.ma.masked_invalid(original_data[:,i_column]).mask\n",
    "            new_column[mask] = 1\n",
    "            if np.sum(new_column) != 0:\n",
    "                new_column = np.expand_dims(new_column, axis=0)\n",
    "                new_column = new_column.transpose()\n",
    "                original_data = np.insert(original_data, [-1], new_column, axis=1)\n",
    "                original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=supply_data[i_column])\n",
    "                new_data = original_data\n",
    "                \n",
    "    elif method == 'imputation':\n",
    "        # to do\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print('Invalid option for treating missing data.')\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "# Transform data into something (hopefully) more useful\n",
    "def get_trans_data(data):\n",
    "    tdata = []\n",
    "    for i in range(len(data)):\n",
    "        pt = []\n",
    "        for idx in range(2, 6):\n",
    "            pt.append(data[i][idx])\n",
    "        for idx in range(16, len(data[i])):\n",
    "            pt.append(data[i][idx])\n",
    "        # add last price / med price\n",
    "        div_price = data[i][0] / data[i][1]\n",
    "        pt.append(div_price)\n",
    "        # add ask spread\n",
    "        ask_spread = data[i][11] - data[i][15]\n",
    "        pt.append(ask_spread)\n",
    "        # add bid spread\n",
    "        bid_spread = data[i][6] - data[i][10]\n",
    "        pt.append(bid_spread)\n",
    "        \n",
    "        tdata.append(pt)\n",
    "    return tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0034e+03 4.0031e+03 2.0000e+00 1.0000e+00 3.0000e+00 1.0000e+00\n",
      " 4.0028e+03 4.0026e+03 4.0024e+03 4.0022e+03 4.0020e+03 4.0034e+03\n",
      " 4.0036e+03 4.0038e+03 4.0040e+03 4.0042e+03 4.0000e+00 2.0000e+00\n",
      " 5.0000e+00 1.3000e+01 6.0000e+00 2.0000e+00 2.0000e+00 1.0000e+00\n",
      " 3.0000e+00 1.5000e+01]\n",
      "[2.0, 1.0, 3.0, 1.0, 4.0, 2.0, 5.0, 13.0, 6.0, 2.0, 2.0, 1.0, 3.0, 15.0, 1.0000749419200121, -0.7999999999997272, 0.8000000000001819]\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "\n",
    "# Parse from csv files\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "# Convert data and deal with missing values\n",
    "dtrain = df_train.values[1:]\n",
    "dtest = df_test.values[:]\n",
    "dtest = missing_values(dtest, method = \"zeros\")\n",
    "dtrain = missing_values(dtrain, method = \"zeros\")\n",
    "\n",
    "# Separate validation and training data\n",
    "X_all, Y_all = dtrain[:, :-1], dtrain[:, -1]\n",
    "X_val = X_all[0:10000]\n",
    "X_train = X_all[10000:(len(X_all) - 1)]\n",
    "Y_val = Y_all[0:10000]\n",
    "Y_train = Y_all[10000:(len(Y_all) - 1)]\n",
    "ran_train = list(zip(X_train, Y_train))\n",
    "random.shuffle(ran_train)\n",
    "X_train, Y_train = zip(*ran_train)\n",
    "X_test = dtest\n",
    "\n",
    "print(X_train[0])\n",
    "X_train_t = get_trans_data(X_train)\n",
    "print(X_train_t[0])\n",
    "X_val_t = get_trans_data(X_val)\n",
    "X_test_t = get_trans_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to make and train classifiers\n",
    "\n",
    "# Make and train a RandomForestClassifier\n",
    "def get_forest(n_estimators, depth, X, Y):\n",
    "    clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = depth, criterion = 'gini')\n",
    "    clf.fit(X, Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf1 validation error: 0.6292913989590955\n",
      "rf2 validation error: 0.6282488117564492\n",
      "gbc validation error: 0.6356715027087586\n",
      "eclf validation error: 0.6331601687343116\n"
     ]
    }
   ],
   "source": [
    "# Try out Voting Classifier\n",
    "\n",
    "train_size = 100000\n",
    "\n",
    "X = X_train_t[:train_size]\n",
    "Y = Y_train[:train_size]\n",
    "random_state = 54321\n",
    "\n",
    "test_trains = True\n",
    "\n",
    "clfs = []\n",
    "wts = []\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=1000, criterion='entropy',  n_jobs = -1,  random_state=random_state, max_depth=5)\n",
    "if test_trains:\n",
    "    rf1.fit(X, Y)\n",
    "    # Get validation error\n",
    "    val_probs = rf1.predict_proba(X_val_t)[:,1]\n",
    "    val_err = roc_auc_score(Y_val, val_probs)\n",
    "    print(\"rf1 validation error:\", val_err)\n",
    "clfs.append(('rf1', rf1))\n",
    "wts.append(1)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, criterion='gini',  n_jobs = -1, random_state=random_state, max_depth=5)\n",
    "if test_trains:\n",
    "    rf2.fit(X, Y)\n",
    "    val_probs = rf2.predict_proba(X_val_t)[:,1]\n",
    "    val_err = roc_auc_score(Y_val, val_probs)\n",
    "    print(\"rf2 validation error:\", val_err)\n",
    "clfs.append(('rf2', rf2))\n",
    "wts.append(1)\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "if test_trains:\n",
    "    gbc.fit(X, Y)\n",
    "    val_probs = gbc.predict_proba(X_val_t)[:,1]\n",
    "    val_err = roc_auc_score(Y_val, val_probs)\n",
    "    print(\"gbc validation error:\", val_err)\n",
    "clfs.append(('gbc', gbc))\n",
    "wts.append(1)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=clfs, voting='soft')\n",
    "eclf.fit(X, Y)\n",
    "val_probs = eclf.predict_proba(X_val_t)[:,1]\n",
    "val_err = roc_auc_score(Y_val, val_probs)\n",
    "print(\"eclf validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = eclf.predict_proba(X_test_t)[:,1]\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "Validation error: 0.6347575003381289\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = 300000\n",
    "\n",
    "X = X_train_t[:train_size]\n",
    "Y = Y_train[:train_size]\n",
    "\n",
    "n_estimators = 400\n",
    "depth = 8\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = depth, criterion = 'gini')\n",
    "clf.fit(X, Y)\n",
    "print(\"Done training\")\n",
    "\n",
    "y_val_pred = clf.predict_proba(X_val_t)[:,1]\n",
    "val_err = roc_auc_score(Y_val, y_val_pred)\n",
    "print(\"Validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = clf.predict_proba(X_test_t)[:, 1]\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
