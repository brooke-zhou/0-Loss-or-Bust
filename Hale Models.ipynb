{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification error definition\n",
    "def classification_err(y, real_y):\n",
    "    len_data = y.size\n",
    "    num_diff = 0.0\n",
    "    for i in range(len_data):\n",
    "        if (y[i] != real_y[i]):\n",
    "            num_diff += 1.0\n",
    "    return (num_diff / len_data)\n",
    "\n",
    "def missing_values(original_data, method='omit', \n",
    "                   supply_data=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "                                15,16,17,18,19,20,21,22,23,24,25,26]):\n",
    "    \"\"\"\n",
    "    Replace missing values in original data according to given rules.\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_data : numpy array\n",
    "        The data set containing NaN.\n",
    "    method : str, optional\n",
    "        'omit' : remove rows containing NaN. Default.\n",
    "        'mean' : replace NaN by the mean of its column.\n",
    "        'median' : replace NaN by the median of its column.\n",
    "        'zeros' : replace NaN by 0.\n",
    "        'change_and_add_flags' : replace NaN by the values specified in \n",
    "         supply_data at each corresponding columns. Then add new columns \n",
    "         with 0 = not NaN and 1 = is NaN.\n",
    "    supply_data : list of floats, optional\n",
    "        values to replace NaN in each column. The default is \n",
    "        [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26].\n",
    "        'imputation' : fill in missing values by simple machine learning\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : numpy array of size (row_original_data, \n",
    "               column_original_data + n_column_containing_missing)\n",
    "        The processed data array.\n",
    "    \"\"\"\n",
    "    if method == 'omit':\n",
    "        new_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        \n",
    "    elif method == 'mean':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        mean_row = np.mean(non_nan_data, axis=0)\n",
    "        for i_column in range(len(mean_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=mean_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'median':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        median_row = np.median(non_nan_data, axis=0)\n",
    "        for i_column in range(len(median_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=median_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'zeros':\n",
    "        new_data = np.nan_to_num(original_data, nan=0.0)\n",
    "        \n",
    "    elif method == 'change_and_add_flags':\n",
    "        import numpy.ma as ma\n",
    "        for i_column in range(27): # 27 columns in total, not including y\n",
    "            new_column = np.zeros(len(original_data[:,i_column]))\n",
    "            mask = np.ma.masked_invalid(original_data[:,i_column]).mask\n",
    "            new_column[mask] = 1\n",
    "            if np.sum(new_column) != 0:\n",
    "                new_column = np.expand_dims(new_column, axis=0)\n",
    "                new_column = new_column.transpose()\n",
    "                original_data = np.insert(original_data, [-1], new_column, axis=1)\n",
    "                original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=supply_data[i_column])\n",
    "                new_data = original_data\n",
    "                \n",
    "    elif method == 'imputation':\n",
    "        # to do\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print('Invalid option for treating missing data.')\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "# don't need labels\n",
    "dtrain = df_train.values[1:]\n",
    "dtest = df_test.values[:]\n",
    "dtest = missing_values(dtest, method = \"mean\")\n",
    "\n",
    "random.shuffle(dtrain)\n",
    "\n",
    "X_all, Y_all = dtrain[:, :-1], dtrain[:, -1]\n",
    "\n",
    "X_val = X_all[0:10000]\n",
    "X_train = X_all[10000:20000]\n",
    "Y_val = Y_all[0:10000]\n",
    "Y_train = Y_all[10000:20000]\n",
    "\n",
    "X_test = dtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "Validation error: 0.1946\n",
      "[0.50803902 0.31900985 0.36530101 ... 0.45036081 0.38811123 0.50767695]\n"
     ]
    }
   ],
   "source": [
    "# Try out random forest\n",
    "\n",
    "n_estimators = 1000\n",
    "depth = 15\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = depth, criterion = 'gini')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done training\")\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "#print(y_val_pred)\n",
    "val_err = classification_err(y_val_pred, Y_val)\n",
    "print(\"Validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = clf.predict_proba(X_test)[:, 1]\n",
    "print(test_probs)\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "Validation error: 0.2246\n"
     ]
    }
   ],
   "source": [
    "# Try out SVM\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', probability=True, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done training\")\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "#print(y_val_pred)\n",
    "val_err = classification_err(y_val_pred, Y_val)\n",
    "print(\"Validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = clf.predict_proba(X_test)[:, 1]\n",
    "print(test_probs)\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
