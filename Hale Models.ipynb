{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification error definition\n",
    "def classification_err(y, real_y):\n",
    "    len_data = y.size\n",
    "    num_diff = 0.0\n",
    "    for i in range(len_data):\n",
    "        if (y[i] != real_y[i]):\n",
    "            num_diff += 1.0\n",
    "    return (num_diff / len_data)\n",
    "\n",
    "def missing_values(original_data, method='omit', \n",
    "                   supply_data=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "                                15,16,17,18,19,20,21,22,23,24,25,26]):\n",
    "    \"\"\"\n",
    "    Replace missing values in original data according to given rules.\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_data : numpy array\n",
    "        The data set containing NaN.\n",
    "    method : str, optional\n",
    "        'omit' : remove rows containing NaN. Default.\n",
    "        'mean' : replace NaN by the mean of its column.\n",
    "        'median' : replace NaN by the median of its column.\n",
    "        'zeros' : replace NaN by 0.\n",
    "        'change_and_add_flags' : replace NaN by the values specified in \n",
    "         supply_data at each corresponding columns. Then add new columns \n",
    "         with 0 = not NaN and 1 = is NaN.\n",
    "    supply_data : list of floats, optional\n",
    "        values to replace NaN in each column. The default is \n",
    "        [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26].\n",
    "        'imputation' : fill in missing values by simple machine learning\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : numpy array of size (row_original_data, \n",
    "               column_original_data + n_column_containing_missing)\n",
    "        The processed data array.\n",
    "    \"\"\"\n",
    "    if method == 'omit':\n",
    "        new_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        \n",
    "    elif method == 'mean':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        mean_row = np.mean(non_nan_data, axis=0)\n",
    "        for i_column in range(len(mean_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=mean_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'median':\n",
    "        non_nan_data = original_data[~np.isnan(original_data).any(axis=1)]\n",
    "        median_row = np.median(non_nan_data, axis=0)\n",
    "        for i_column in range(len(median_row)):\n",
    "            original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=median_row[i_column])\n",
    "            new_data = original_data\n",
    "            \n",
    "    elif method == 'zeros':\n",
    "        new_data = np.nan_to_num(original_data, nan=0.0)\n",
    "        \n",
    "    elif method == 'change_and_add_flags':\n",
    "        import numpy.ma as ma\n",
    "        for i_column in range(27): # 27 columns in total, not including y\n",
    "            new_column = np.zeros(len(original_data[:,i_column]))\n",
    "            mask = np.ma.masked_invalid(original_data[:,i_column]).mask\n",
    "            new_column[mask] = 1\n",
    "            if np.sum(new_column) != 0:\n",
    "                new_column = np.expand_dims(new_column, axis=0)\n",
    "                new_column = new_column.transpose()\n",
    "                original_data = np.insert(original_data, [-1], new_column, axis=1)\n",
    "                original_data[:,i_column] = np.nan_to_num(original_data[:,i_column], \n",
    "                                                      nan=supply_data[i_column])\n",
    "                new_data = original_data\n",
    "                \n",
    "    elif method == 'imputation':\n",
    "        # to do\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print('Invalid option for treating missing data.')\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "# don't need labels\n",
    "dtrain = df_train.values[1:]\n",
    "dtest = df_test.values[:]\n",
    "dtest = missing_values(dtest, method = \"mean\")\n",
    "\n",
    "random.shuffle(dtrain)\n",
    "\n",
    "X_all, Y_all = dtrain[:, :-1], dtrain[:, -1]\n",
    "\n",
    "X_val = X_all[0:10000]\n",
    "X_train = X_all[10000:200000]\n",
    "Y_val = Y_all[0:10000]\n",
    "Y_train = Y_all[10000:200000]\n",
    "\n",
    "X_test = dtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "Validation error: 0.2\n",
      "[0.54263202 0.24408337 0.3127382  ... 0.41443658 0.39582491 0.50916129]\n"
     ]
    }
   ],
   "source": [
    "# Try out random forest\n",
    "\n",
    "n_estimators = 1000\n",
    "depth = 15\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators, max_depth = depth, criterion = 'gini')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done training\")\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "#print(y_val_pred)\n",
    "val_err = classification_err(y_val_pred, Y_val)\n",
    "print(\"Validation error:\", val_err)\n",
    "\n",
    "# Make submission\n",
    "test_probs = clf.predict_proba(X_test)[:, 1]\n",
    "print(test_probs)\n",
    "test[\"Predicted\"] = test_probs\n",
    "test[[\"id\",\"Predicted\"]].to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
